var tipuesearch = {"pages": [{
    "title": "NAVER API를 사용해서 크롤링하기 - 2",
    "text": "이전 포스팅에서 네이버 API를 신청하고, 내 애플리케이션까지 등록해서 API를 사용할 때 필요한 Client ID와 Secret을 모두 발급을 받았다. 그리고 API Documents에서 검색 API에 관한 내용을 찾아서 아래의 Python 예제 코드까지 확인했는데 코드를 확인해보자. import os import sys import urllib.request client_id = \"YOUR_CLIENT_ID\" client_secret = \"YOUR_CLIENT_SECRET\" encText = urllib.parse.quote(\"검색할 단어\") url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # json 결과 # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과 request = urllib.request.Request(url) request.add_header(\"X-Naver-Client-Id\",client_id) request.add_header(\"X-Naver-Client-Secret\",client_secret) response = urllib.request.urlopen(request) rescode = response.getcode() if(rescode==200): response_body = response.read() print(response_body.decode('utf-8')) else: print(\"Error Code:\" + rescode) 내 애플리케이션 인증 client_id = \"YOUR_CLIENT_ID\" client_secret = \"YOUR_CLIENT_SECRET\" 우선 이 부분은 내가 네이버 API를 사용하기 전에 나라는 걸 인증하는 인증키와 키를 입력하는 부분이다. 이전 포스팅에서 내 애플리케이션에서 발급받은 Client ID와 Client Secret을 여기에 입력하면 된다. 검색 키워드 Parsing encText = urllib.parse.quote(\"검색할 단어\") 네이버 뉴스, 쇼핑, 블로그 등에서 특정한 글을 찾고 싶을 때 검색할 단어를 입력한다. 크롤링을 할 때도 어떤 단어를 기반으로 검색할 것인지 검색할 단어를 입력한다. 하지만, 내가 검색할 단어에 특수문자가 포함 되어있으면 특수문자 그대로 전달을 할 수 없다. 한글도 특수문자에 해당한다. 따라서 인코딩 작업이 필요한데 quote 함수가 인코딩 작업을 해준다. “코로나”를 인코딩하면 다음과 같이 나온다. import urllib Encoding_word = urllib.parse.quote(\"코로나\") print (Encoding_word) '%EC%BD%94%EB%A1%9C%EB%82%98' 요청 URL url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # json 결과 # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과 검색할 단어까지 확인됐으면, 단어를 매개변수로 포함해서 요청할 URL 주소가 완성된다. 요청한 URL에 대한 응답 결과를 받을 때 2가지 방식의 출력 포맷으로 제공해준다. 아래 그림에서 보는 것처럼 XML과 JSON 형태로 제공된다. default로 JSON 출력 포맷의 결과를 제공해주는데 XML 결과로 받고 싶으면 blog.xml로 요청해주면 된다. 요청 &amp; 응답 request = urllib.request.Request(url) request.add_header(\"X-Naver-Client-Id\",client_id) request.add_header(\"X-Naver-Client-Secret\",client_secret) response = urllib.request.urlopen(request) ##요청 &amp; 응답 rescode = response.getcode() if(rescode==200): response_body = response.read() print(response_body.decode('utf-8')) else: print(\"Error Code:\" + rescode) Naver 블로그 서버에 요청할 객체를 생성하고, 나를 인증하는 id와 secret 정보를 헤더에 포함해서 요청을 한다. 요청 처리에 대한 응답을 response에 저장하고 getcode() 함수로 상태 코드를 알아낸다. 웹 페이지가 제대로 요청이 되었으면 일반적으로 HTTP 코드 200을 반환한다. 응답 코드가 200이면 read() 함수로 데이터를 읽어서 출력해서 확인하면 된다. 응답한 내용은 바이트 타입이므로 UTF-8 디코딩을 통해 문자열로 변경한다. “코로나”라는 단어로 검색한 결과를 확인하면 다음과 같다. 출력된 결과가 의미하는 것들은 출력 결과 설명 부분을 확인하면 알 수 있다. API를 사용해서 받은 블로그 검색 결과와 네이버 블로그 홈페이지에서 코로나를 직접 입력해서 나온 결과를 비교해보면 첫 번째 글의 제목이 “코로나 백신 (아스트라제네카)…” 로 같은 것을 확인할 수 있다. 혹시라도 요청이 부적절하거나 오타가 나는 등의 이유로 요청이 이루어지지 않은 경우 에러코드를 출력하는데 다음과 같은 에러들이 있다. 요청 변수 위에 “코로나” 블로그 검색 결과를 살펴보면 결과 Key 값들 중에 start, display를 확인할 수 있다. start는 검색 시작 위치를 몇 번째 글부터 시작할지, display는 총 몇 개의 글을 출력할 것인지 건수를 정하는 변수다. 내가 처음에 요청한 결과는 URL에서 필수 변수에 해당하는 검색 단어 query만 입력했다. query 이외에도 display, start와 유사도 또는 날짜순으로 정렬을 할 수 있는 sort 옵션까지 요청 변수를 추가할 수 있다. 요청 변수는 다음과 같다. 요청 변수를 모두 사용해서 요청하는 예제는 다음과 같다. curl \"https://openapi.naver.com/v1/search/blog.xml?query=%EB%A6%AC%EB%B7%B0&amp;display=10&amp;start=1&amp;sort=sim\" \\ -H \"X-Naver-Client-Id: {애플리케이션 등록 시 발급받은 client id 값}\" \\ -H \"X-Naver-Client-Secret: {애플리케이션 등록 시 발급받은 client secret 값}\" -v query가 무엇인지 확인하기 위해서 quote parsing을 반대로 진행한다. urllib.parse.unquote(\"%EB%A6%AC%EB%B7%B0\") \"리뷰\" 검색할 단어는 리뷰이며, 검색할 건수는 10건이며, 시작은 첫 번째 글부터 시작하며, 유사도 정렬 순으로 출력을 했다. 만약 시작을 15번째 글부터 시작해서 100건을 날짜순으로 출력하고 싶으면 다음과 같이 요청 URL을 사용하면 된다. url = \"https://openapi.naver.com/v1/search/blog.xml?query=%EB%A6%AC%EB%B7%B0&amp;display=100&amp;start=15&amp;sort=date\" 또한, 블로그가 아니라 뉴스, 카페, 영화, 쇼핑 등 다른 카테고리의 검색 결과를 요청하고 싶으면 “blog”를 “news”, “cafearticle”, “movie”, “shop” 으로 변경할 수도 있다. 이는 API 검색 문서에서 다른 카테고리들을 확인해보면 알 수 있다.",
    "tags": "crawling development",
    "url": "/development/2021/03/31/crawling_naver_api-2/"
  },{
    "title": "iTerm2 + Zsh + Oh My Zsh 설치 &amp; 설정하기",
    "text": "맥을 설치하면 기본으로 Terminal이 설치되어있지만 사용하기에 불편하고 멋있어(?) 보이지 않아서 다른 터미널을 설치해서 사용하려고 한다. 맥에서 가장 많이 추천되고 오랫동안 내가 사용해온 iTerm2 + zsh 를 설치하고 설정하는 방법을 알아보자. iTerm2를 사용하면서 가장 유용했던 기능은 화면 분할 기능이다. 데이터 크롤링을 하는데 10대 이상의 컴퓨터를 동시에 접속해서 관리 하는데 기본 터미널로만은 너무 힘들어서 화면 분할도 되고 다른 많은 기능도 있는 iTerm2를 찾게 됐다. 설치를 하고 설정을 해보자. iTerm2 + Zsh + Oh My Zsh 설치 1. iTerm2 설치 아래 링크에 들어가서 다운받고 알집을 풀어서 설치하면 된다. iTerm2 홈페이지: https://iterm2.com/ iTerm2 기본 설치 화면이다. 2. Zsh 설치 그런데 터미널의 제목표시줄을 보면 zsh가 기본 쉘로 이미 설정된 것을 볼 수 있다. 확인해보니, MacOS 10.15버전인 카탈리나부터 기본 쉘이 bash에서 zsh로 변경되어서 OS를 설치하면서 기본으로 설치되어 있다. 현재 내 컴퓨터에 어떤 쉘들이 설치되어 있는지 확인하려면 다음과 같은 명령으로 확인할 수 있다. cat /etc/shells Zsh를 설치하기 위해서는 MacOS 패키지 관리 프로그램인 Homebrew를 사용해서 설치하면 된다. Homebrew를 설치하는 방법은 Homebrew 설치 &amp; 사용하기를 참고하면 된다. 다음과 같은 쉘들이 기본으로 설치된 것을 확인할 수 있다. 만약, 기본 쉘을 zsh에서 bash로 변경하고 싶으면 다음 명령어를 사용하면 된다. chsh -s /bin/bash 3. Oh My Zsh 설치 다음으로는 쉘을 사용하는데 도움을 많이 주는 Oh My Zsh을 설치한다. Oh My Zsh은 타이핑 교정, 명령어 추천, 자동 완성 기능등 여러가지 기능이 있다. 설치는 아래 사이트에서 설치 명령어를 찾아서 하면 된다. https://ohmyz.sh/#install https://github.com/ohmyzsh/ohmyzsh sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"",
    "tags": "etc environment",
    "url": "/environment/2021/03/30/iterm_install/"
  },{
    "title": "Homebrew 설치 &amp; 사용하기",
    "text": "Homebrew 설치하기 MacOS를 설치하고 가장 먼저 해야될 일중에 하나가 MacOS 패키지 관리 프로그램인 Homebrew를 설정하는 것이다. 리눅스에서는 yum, apt와 같은 역할을 한다고 볼수있다. 설치하는 방법은 아래 링크로 들어가서 확인하거나 아래 명령어를 실행하면 된다. Homebrew 홈페이지: https://brew.sh/index_ko $ /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" 참고로 curl과 ssl을 사용하기 전에는 kaspersky같은 보안 프로그램이나 vpn을 켜놓았으면 꼭 끄고 위 명령어를 실행하세요. Homebrew 사용하기 패키지 설치 $ brew install &lt;Package name&gt; 패키지 삭제 $ brew remove &lt;Package name&gt; 패키지 업그레이드 $ brew upgrade &lt;Package name&gt;",
    "tags": "etc environment",
    "url": "/environment/2021/03/30/homebrew_install/"
  },{
    "title": "NAVER API를 사용해서 크롤링하기 - 1",
    "text": "1. 네이버 개발자 API 가입 &amp; 이용 신청 네이버 API를 사용하기 위해서는 우선 네이버 개발자 센터에 가입하고 오픈 API 이용 신청을 해야 한다. 아래 링크에 들어가서 신청을 한다. 네이버 개발자 센터 : https://developers.naver.com/main/ 개발자 센터 메인 페이지에서 [Application] - [애플리케이션 등록]을 누르고 약관 동의, 계정 정보 등록을 하면 아래와 같이 애플리케이션 등록을 할 수 있다. 애플리케이션 이름은 적당히 내가 원하는 이름을 적고, 사용 API에는 여러 가지가 있지만 나는 검색 API를 사용할 예정이므로 검색을 선택한다. 비 로그인 오픈 API 서비스 환경에는 Android, IOS, WEB 설정 이렇게 3가지가 있는데, 나는 로컬 컴퓨터 WEB 환경에서 사용하므로 WEB만 선택하고 URL은 http://localhost를 입력하고 등록한다. 등록에 완료하면 위와 같이 내가 등록한 애플리케이션에 대한 정보를 볼 수 있다. Client ID와 Client Secret은 네이버 API를 사용할 때 코드에 입력해야 하므로 따로 기록해 놓는다. 일반적인 사용자들은 하단에 보이는 것처럼 하루 API 사용량이 25,000번으로 제한되어 있다. 일일 사용량을 초과해서 사용하려면 왼쪽에 API 제휴 신청을 하면 된다. 2. 검색 API Documents 네이버 개발자 메인 페이지 상단에서 [Documents] - [서비스 API] - [검색]을 선택하면 검색 API에 대한 Documents를 아래와 같이 확인할 수 있다. 페이지를 내려서 확인해보면 Python 코드를 확인할 수 있다. 블로그 검색 API Python 코드 예제 # 네이버 검색 API예제는 블로그를 비롯 전문자료까지 호출방법이 동일하므로 blog검색만 대표로 예제를 올렸습니다. # 네이버 검색 Open API 예제 - 블로그 검색 import os import sys import urllib.request client_id = \"YOUR_CLIENT_ID\" client_secret = \"YOUR_CLIENT_SECRET\" encText = urllib.parse.quote(\"검색할 단어\") url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText # json 결과 # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과 request = urllib.request.Request(url) request.add_header(\"X-Naver-Client-Id\",client_id) request.add_header(\"X-Naver-Client-Secret\",client_secret) response = urllib.request.urlopen(request) rescode = response.getcode() if(rescode==200): response_body = response.read() print(response_body.decode('utf-8')) else: print(\"Error Code:\" + rescode) 다음 포스팅에서는 아래의 Python 코드를 사용해서 데이터를 실제로 크롤링을 해보자. NAVER API를 사용해서 크롤링하기 - 2",
    "tags": "crawling development",
    "url": "/development/2021/03/29/crawling_naver_api-1/"
  },{
    "title": "selenium을 사용한 데이터 크롤링하기",
    "text": "사전 설치 1. Selenium &amp; BeautifulSoup설치하기 pip install selenium pip install BeautifulSoup4 2. 구글 웹 드라이브 설치 &amp; 다운로드 Selenium을 사용해서 크롤링을 하기 위해서는 웹 드라이브가 필요하다. 나는 구글 웹 드라이브를 사용해본다. 구글 웹 드라이브 다운로드 홈페이지 : https://chromedriver.chromium.org/downloads 다운로드 홈페이지에 접속하면 아래와 같이 다운을 받을수가 있다. 아래에서 다운을 받을 때, 주의 해야 할 부분이 있는데 내가 사용하는 크롬의 버전과 일치를 해야한다. 나의 크롬 정보를 살펴보기 위해서 크롬에서 Settings - About Chrome 으로 들어가 확인을 해본다. 크롬의 버전이 89.0.~ 이므로 89 버전의 웹 드라이버를 다운받는다.",
    "tags": "crawling development",
    "url": "/development/2021/02/25/crawling_selenium/"
  },{
    "title": "Jupyter Notebook에 가상환경 커널 추가하기",
    "text": "먼저 virtualenv를 사용해서 가상환경을 만들고 활성화 시켜줍니다. virtualenv -p python2.7 ~/Desktop/py27 source ~/Desktop/py27/bin/active pip install notebook ipykernel 그 다음으로 notebook과 ipykernel을 설치합니다. pip install notebook ipykernel Jupyter Notebook에 새로 만든 가상환경을 추가합니다. python -m ipykernel install --user --name [가상환경 이름] --display-name \"[Jupyter notebook에 등록되는 이름]\" python -m ipykernel install --user --name py27 --display-name \"py27_test\" 완료가 되었으면 Jupyter Notebook을 실행시켜서 살펴보면 다음과 같이 확인 할 수 있습니다.",
    "tags": "python environment",
    "url": "/environment/2021/02/16/virtualenv-add-jupyter/"
  },{
    "title": "Using both Python 2.x &amp; 3.x",
    "text": "python2.x 설정 virtualenv -p python2.7 ~/Desktop/py27 source ~/Desktop/py27/bin/active pip install notebook ipykernel ipython kernel install --user python3.x 설정 virtualenv -p python3 ~/Desktop/py3 source ~/Desktop/py3/bin/active pip3 install notebook ipykernel ipython kernel install --user",
    "tags": "python environment",
    "url": "/environment/2021/02/16/python2_3/"
  },{
    "title": "Docker Command",
    "text": "Docker 이미지 가져오기 docker pull [image name]",
    "tags": "docker environment",
    "url": "/environment/2021/02/04/docker-command/"
  }]};